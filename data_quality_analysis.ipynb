{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda5c504",
   "metadata": {},
   "source": [
    "# Data Quality Analysis - Bronze Layer\n",
    "\n",
    "This notebook performs comprehensive data quality checks on the raw data files to identify:\n",
    "- Missing values\n",
    "- Data Type Validation\n",
    "- Non-numeric values in numeric columns\n",
    "- Duplicate records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca94d48",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea637fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f3a34e",
   "metadata": {},
   "source": [
    "## 2. Load Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4be27a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shapes:\n",
      "  Attributes: (12500, 6)\n",
      "  Financials: (12500, 22)\n",
      "  Clickstream: (215376, 22)\n",
      "  Loan Daily: (137500, 11)\n"
     ]
    }
   ],
   "source": [
    "# Define data directory\n",
    "data_dir = \"data\"\n",
    "\n",
    "# Load all data files\n",
    "df_attributes = pd.read_csv(os.path.join(data_dir, \"features_attributes.csv\"))\n",
    "df_financials = pd.read_csv(os.path.join(data_dir, \"features_financials.csv\"))\n",
    "df_clickstream = pd.read_csv(os.path.join(data_dir, \"feature_clickstream.csv\"))\n",
    "df_loan_daily = pd.read_csv(os.path.join(data_dir, \"lms_loan_daily.csv\"))\n",
    "\n",
    "# Display dataset shapes\n",
    "print(\"Dataset Shapes:\")\n",
    "print(f\"  Attributes: {df_attributes.shape}\")\n",
    "print(f\"  Financials: {df_financials.shape}\")\n",
    "print(f\"  Clickstream: {df_clickstream.shape}\")\n",
    "print(f\"  Loan Daily: {df_loan_daily.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb651c",
   "metadata": {},
   "source": [
    "## 3. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49483a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Attributes Dataset:\n",
      "No missing values found!\n",
      "\n",
      "Missing Values in Financials Dataset:\n",
      "      Column  Missing_Count  Missing_Percentage\n",
      "Type_of_Loan           1426               11.41\n",
      "\n",
      "Missing Values in Clickstream Dataset:\n",
      "No missing values found!\n",
      "\n",
      "Missing Values in Loan Daily Dataset:\n",
      "No missing values found!\n"
     ]
    }
   ],
   "source": [
    "def analyze_missing_values(df, dataset_name):\n",
    "    \"\"\"Analyze and display missing values in a dataframe\"\"\"\n",
    "    missing = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Missing_Count': df.isnull().sum(),\n",
    "        'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "    })\n",
    "    missing = missing[missing['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "    \n",
    "    print(f\"\\nMissing Values in {dataset_name} Dataset:\")   \n",
    "    if len(missing) > 0:\n",
    "        print(missing.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No missing values found!\")\n",
    "    \n",
    "    return missing\n",
    "\n",
    "# Analyze missing values for all datasets\n",
    "missing_attributes = analyze_missing_values(df_attributes, \"Attributes\")\n",
    "missing_financials = analyze_missing_values(df_financials, \"Financials\")\n",
    "missing_clickstream = analyze_missing_values(df_clickstream, \"Clickstream\")\n",
    "missing_loan_daily = analyze_missing_values(df_loan_daily, \"Loan Daily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5993ee3d",
   "metadata": {},
   "source": [
    "## 4. Data Type Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3863c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Data Types:\n",
      "\n",
      "Attributes:\n",
      "Customer_ID      object\n",
      "Name             object\n",
      "Age              object\n",
      "SSN              object\n",
      "Occupation       object\n",
      "snapshot_date    object\n",
      "dtype: object\n",
      "\n",
      "Financials:\n",
      "Customer_ID                  object\n",
      "Annual_Income                object\n",
      "Monthly_Inhand_Salary       float64\n",
      "Num_Bank_Accounts             int64\n",
      "Num_Credit_Card               int64\n",
      "Interest_Rate                 int64\n",
      "Num_of_Loan                  object\n",
      "Type_of_Loan                 object\n",
      "Delay_from_due_date           int64\n",
      "Num_of_Delayed_Payment       object\n",
      "Changed_Credit_Limit         object\n",
      "Num_Credit_Inquiries        float64\n",
      "Credit_Mix                   object\n",
      "Outstanding_Debt             object\n",
      "Credit_Utilization_Ratio    float64\n",
      "Credit_History_Age           object\n",
      "Payment_of_Min_Amount        object\n",
      "Total_EMI_per_month         float64\n",
      "Amount_invested_monthly      object\n",
      "Payment_Behaviour            object\n",
      "Monthly_Balance              object\n",
      "snapshot_date                object\n",
      "dtype: object\n",
      "\n",
      "Loan_Daily:\n",
      "loan_id             object\n",
      "Customer_ID         object\n",
      "loan_start_date     object\n",
      "tenure               int64\n",
      "installment_num      int64\n",
      "loan_amt             int64\n",
      "due_amt            float64\n",
      "paid_amt           float64\n",
      "overdue_amt        float64\n",
      "balance            float64\n",
      "snapshot_date       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define expected numeric columns for each dataset\n",
    "expected_numeric_columns = {\n",
    "    'Attributes': ['Age'],\n",
    "    'Financials': ['Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', \n",
    "                   'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', \n",
    "                   'Delay_from_due_date', 'Num_of_Delayed_Payment', \n",
    "                   'Changed_Credit_Limit', 'Num_Credit_Inquiries', \n",
    "                   'Outstanding_Debt', 'Credit_Utilization_Ratio', \n",
    "                   'Total_EMI_per_month', 'Amount_invested_monthly', 'Monthly_Balance'],\n",
    "    'Loan_Daily': ['tenure', 'installment_num', 'loan_amt', 'due_amt', \n",
    "                   'paid_amt', 'overdue_amt', 'balance']\n",
    "}\n",
    "\n",
    "# Display current data types\n",
    "print(\"\\nCurrent Data Types:\")\n",
    "\n",
    "for name, df in [('Attributes', df_attributes), ('Financials', df_financials), \n",
    "                 ('Loan_Daily', df_loan_daily)]:\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0d5f6",
   "metadata": {},
   "source": [
    "## 5. Check for Non-Numeric Values in Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39337107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking Non-Numeric Values in Attributes Dataset:\n",
      "\n",
      "Age:\n",
      "  Count: 637\n",
      "  Sample values: ['40_', '46_', '3843_', '30_', '24_', '22_', '32_', '26_', '34_', '41_']\n",
      "\n",
      "Checking Non-Numeric Values in Financials Dataset:\n",
      "\n",
      "Annual_Income:\n",
      "  Count: 859\n",
      "  Sample values: ['52312.68_', '49718.55_', '20652.98_', '28315.95_', '43062.54_', '7645.095_', '93847.86_', '11731.585_', '30739.3_', '28352.24_']\n",
      "\n",
      "Num_of_Loan:\n",
      "  Count: 623\n",
      "  Sample values: ['1_', '6_', '2_', '4_', '3_', '5_', '7_', '0_', '9_', '8_']\n",
      "\n",
      "Num_of_Delayed_Payment:\n",
      "  Count: 374\n",
      "  Sample values: ['18_', '20_', '0_', '9_', '19_', '15_', '16_', '12_', '17_', '11_']\n",
      "\n",
      "Changed_Credit_Limit:\n",
      "  Count: 254\n",
      "  Sample values: ['_']\n",
      "\n",
      "Outstanding_Debt:\n",
      "  Count: 139\n",
      "  Sample values: ['2699.17_', '642.42_', '755.17_', '865.3_', '149.92_', '3375.66_', '1559.16_', '30.31_', '4319.35_', '2817.77_']\n",
      "\n",
      "Amount_invested_monthly:\n",
      "  Count: 558\n",
      "  Sample values: ['__10000__']\n",
      "\n",
      "Monthly_Balance:\n",
      "  Count: 1\n",
      "  Sample values: ['__-333333333333333333333333333__']\n",
      "\n",
      "Checking Non-Numeric Values in Loan Daily Dataset:\n",
      "\n",
      "All numeric columns contain valid numeric values!\n",
      "\n",
      "All numeric columns contain valid numeric values!\n"
     ]
    }
   ],
   "source": [
    "def check_non_numeric_values(df, columns, dataset_name):\n",
    "    \"\"\"Check for non-numeric values in columns that should be numeric\"\"\"\n",
    "    print(f\"\\nChecking Non-Numeric Values in {dataset_name} Dataset:\")\n",
    "    \n",
    "    issues_found = False\n",
    "    \n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        # Convert column to string and check if values can be converted to numeric\n",
    "        temp_series = df[col].astype(str).str.strip()\n",
    "        \n",
    "        # Filter out NaN/None values\n",
    "        temp_series = temp_series[temp_series != 'nan']\n",
    "        \n",
    "        # Try to convert to numeric\n",
    "        numeric_conversion = pd.to_numeric(temp_series, errors='coerce')\n",
    "        non_numeric_mask = numeric_conversion.isna() & (temp_series != '')\n",
    "        \n",
    "        if non_numeric_mask.sum() > 0:\n",
    "            issues_found = True\n",
    "            non_numeric_values = df[col][non_numeric_mask.values].unique()\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Count: {non_numeric_mask.sum()}\")\n",
    "            print(f\"  Sample values: {list(non_numeric_values[:10])}\")\n",
    "    \n",
    "    if not issues_found:\n",
    "        print(\"\\nAll numeric columns contain valid numeric values!\")\n",
    "\n",
    "# Check each dataset\n",
    "check_non_numeric_values(df_attributes, expected_numeric_columns['Attributes'], \"Attributes\")\n",
    "check_non_numeric_values(df_financials, expected_numeric_columns['Financials'], \"Financials\")\n",
    "check_non_numeric_values(df_loan_daily, expected_numeric_columns['Loan_Daily'], \"Loan Daily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d115883d",
   "metadata": {},
   "source": [
    "## 6. Check for Duplicate Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e6fc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attributes - Duplicates based on Customer_ID: 0\n",
      "Financials - Duplicates based on Customer_ID: 0\n",
      "Clickstream - Duplicates based on Customer_ID: 206402\n",
      "Loan Daily - Duplicates based on (loan_id, snapshot_date): 0\n"
     ]
    }
   ],
   "source": [
    "# Check duplicates based on key columns\n",
    "if 'Customer_ID' in df_attributes.columns:\n",
    "    dup_attributes = df_attributes.duplicated(subset=['Customer_ID']).sum()\n",
    "    print(f\"\\nAttributes - Duplicates based on Customer_ID: {dup_attributes}\")\n",
    "\n",
    "if 'Customer_ID' in df_financials.columns:\n",
    "    dup_financials = df_financials.duplicated(subset=['Customer_ID']).sum()\n",
    "    print(f\"Financials - Duplicates based on Customer_ID: {dup_financials}\")\n",
    "\n",
    "if 'Customer_ID' in df_clickstream.columns:\n",
    "    dup_clickstream = df_clickstream.duplicated(subset=['Customer_ID']).sum()\n",
    "    print(f\"Clickstream - Duplicates based on Customer_ID: {dup_clickstream}\")\n",
    "\n",
    "if 'loan_id' in df_loan_daily.columns and 'snapshot_date' in df_loan_daily.columns:\n",
    "    dup_loan = df_loan_daily.duplicated(subset=['loan_id', 'snapshot_date']).sum()\n",
    "    print(f\"Loan Daily - Duplicates based on (loan_id, snapshot_date): {dup_loan}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
